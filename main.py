import streamlit as st
import pandas as pd
import numpy as np
from ucimlrepo import fetch_ucirepo
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
import matplotlib.pyplot as plt
import seaborn as sns

# Sayfa YapÄ±landÄ±rmasÄ±
st.set_page_config(
    page_title="ğŸ’³ Kredi OnayÄ± Modelleri Analiz Platformu", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# ----------------------------------------------------------------------
# 1. VERÄ° YÃœKLEME VE MODEL EÄÄ°TÄ°MÄ° (Arka Plan - YALNIZCA BÄ°R KEZ Ã‡ALIÅIR)
# ----------------------------------------------------------------------

@st.cache_resource(show_spinner="â³ Veri yÃ¼kleniyor ve tÃ¼m 6 model eÄŸitiliyor...")
def load_data_and_train_models():
    """TÃ¼m veriyi yÃ¼kler, Ã¶n iÅŸler, eÄŸitir ve sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r."""
    
    try:
        credit_approval = fetch_ucirepo(id=27)
        X = credit_approval.data.features
        y = credit_approval.data.targets
        
    except Exception as e:
        st.error(f"âŒ Veri yÃ¼klenirken hata: {e}")
        return None, None, None
    
    # Ã–n Ä°ÅŸleme (Label Encoding)
    X_processed = X.copy()
    categorical_columns = X_processed.select_dtypes(include=['object']).columns

    for col in categorical_columns:
        le = LabelEncoder()
        X_processed[col] = le.fit_transform(X_processed[col].astype(str))

    if isinstance(y, pd.DataFrame):
        y = y.squeeze()
    if y.dtype == 'object' or isinstance(y.iloc[0], str):
        encoder = LabelEncoder()
        y = encoder.fit_transform(y)

    # Split, Scaling, Imputation
    X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.3, random_state=42)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    imputer = SimpleImputer(strategy='mean')
    X_train_final = imputer.fit_transform(X_train_scaled)
    X_test_final = imputer.transform(X_test_scaled)
    
    # Model EÄŸitimi
    models = {
        "Logistic Regression": LogisticRegression(random_state=42),
        "Decision Tree": DecisionTreeClassifier(random_state=42),
        "Random Forest": RandomForestClassifier(random_state=42),
        "Support Vector Machine (SVM)": SVC(random_state=42),
        "Gradient Boosting Machines (GBM)": GradientBoostingClassifier(random_state=42),
        "Neural Network (MLP)": MLPClassifier(random_state=42, max_iter=300)
    }
    
    results = {}
    
    for name, model in models.items():
        model.fit(X_train_final, y_train)
        y_pred = model.predict(X_test_final)
        
        report = classification_report(y_test, y_pred, output_dict=True)
        
        results[name] = {
            "accuracy": accuracy_score(y_test, y_pred),
            "report": report,
            "conf_matrix": confusion_matrix(y_test, y_pred),
            "precision": report['weighted avg']['precision'],
            "recall": report['weighted avg']['recall'],
        }
    
    X_df = pd.DataFrame(X_processed, columns=X.columns)
    return results, X_df, credit_approval.metadata


# ----------------------------------------------------------------------
# 2. SAYFA FONKSÄ°YONLARI
# ----------------------------------------------------------------------

def show_data_prep_page(X_raw, metadata, results):
    """Veri HazÄ±rlÄ±ÄŸÄ± ve GiriÅŸ sayfasÄ±nÄ± gÃ¶sterir ve tÃ¼m model skorlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±r."""
    
    st.title("ğŸ“š Veri Seti Ä°ncelemesi ve Ã–n Ä°ÅŸleme AdÄ±mlarÄ±")
    
    # --- Veri Seti Ã–zeti ---
    st.header("1ï¸âƒ£ Ã–n Ä°ÅŸleme YapÄ±lmÄ±ÅŸ Veri Seti Ã–n Ä°zlemesi")
    st.info(f"Toplam Ã¶rnek sayÄ±sÄ±: **{X_raw.shape[0]}**, Ã–zellik sayÄ±sÄ±: **{X_raw.shape[1]}**")
    
    st.dataframe(X_raw.head(10), use_container_width=True)

    # --- Ã–n Ä°ÅŸleme AdÄ±mlarÄ± ---
    st.header("2ï¸âƒ£ Uygulanan Veri HazÄ±rlÄ±k SÃ¼reci")
    col_prep, col_info = st.columns(2)
    
    with col_prep:
        st.markdown("""
        * **Veri KaynaÄŸÄ±:** UCI Machine Learning Repository (Credit Approval).
        * **Kategorik DÃ¶nÃ¼ÅŸÃ¼m:** **Label Encoding** uygulandÄ± (**data Subset.ipynb**).
        * **Eksik DeÄŸerler:** **Ortalama (Mean) Imputation** ile dolduruldu (**data Imputation.ipynb**).
        * **Ã–zellik Ã–lÃ§ekleme:** `StandardScaler` ile tÃ¼m deÄŸerler normalize edildi.
        * **BÃ¶lme:** EÄŸitim (%70) ve Test (%30) olarak ayrÄ±ldÄ±.
        """)

    with col_info:
        st.subheader("Veri Seti MetadatalarÄ±")
        # Metadata'dan Ã¶nemli bilgileri Ã§ekip listeleyelim
        if metadata and 'num_instances' in metadata and 'num_features' in metadata:
            st.markdown(f"**Ã–rnek SayÄ±sÄ±:** {metadata['num_instances']}")
            st.markdown(f"**Ã–zellik SayÄ±sÄ±:** {metadata['num_features']}")
            st.markdown(f"**Alan:** {metadata['area']}")
            st.markdown(f"**Ã–zet:** {metadata['abstract'][:150]}...")
    
    st.write("---")
    
    # --- TÃ¼m Modellerin KarÅŸÄ±laÅŸtÄ±rmasÄ± (GÃ¶rsel) ---
    st.header("3ï¸âƒ£ Modellerin Genel DoÄŸruluk KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    
    all_accuracies = {name: res['accuracy'] for name, res in results.items()}
    accuracy_df = pd.DataFrame(all_accuracies.items(), columns=['Model', 'DoÄŸruluk Skoru'])
    
    # GÃ¶rselleÅŸtirme
    fig, ax = plt.subplots(figsize=(10, 5))
    sns.barplot(x='Model', y='DoÄŸruluk Skoru', data=accuracy_df.sort_values(by='DoÄŸruluk Skoru', ascending=False), palette='viridis', ax=ax)
    
    ax.set_title("FarklÄ± SÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±n DoÄŸruluk SkorlarÄ±")
    ax.set_ylabel("DoÄŸruluk (Accuracy)")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    st.pyplot(fig)


def show_model_comparison_page(results):
    """Model KarÅŸÄ±laÅŸtÄ±rma ve SonuÃ§lar sayfasÄ±nÄ± gÃ¶sterir."""
    st.title("ğŸ“ˆ Model Performans DeÄŸerlendirmesi")
    st.markdown("EÄŸitilmiÅŸ modellerden birini seÃ§erek detaylÄ± metriklerini inceleyin.")
    
    # --- Sidebar Model SeÃ§imi ---
    st.sidebar.header("ğŸ¯ Model SeÃ§imi")
    model_name = st.sidebar.selectbox(
        "Ä°ncelenecek Modeli SeÃ§in:",
        list(results.keys()),
        index=2 
    )

    selected_result = results[model_name]

    st.header(f"SeÃ§ilen Model: **{model_name}**")
    st.write("---")

    # --- 1. Temel Metrikler (Metrik KartlarÄ±) ---
    st.subheader("1. Temel Performans Metrikleri")
    
    col_acc, col_prec, col_rec = st.columns(3)
    
    # DoÄŸruluk KartÄ±
    with col_acc:
        st.metric(label="âœ… DoÄŸruluk (Accuracy)", 
                  value=f"{selected_result['accuracy']:.4f}",
                  delta=None) # Delta deÄŸeri, Ã¶nceki sayfadaki en iyi modelle karÅŸÄ±laÅŸtÄ±rma iÃ§in kullanÄ±labilir.
    
    # Kesinlik (Precision) KartÄ±
    with col_prec:
        st.metric(label="ğŸ” Ortalama Kesinlik (Precision)",
                  value=f"{selected_result['precision']:.4f}")
    
    # Geri Ã‡aÄŸÄ±rma (Recall) KartÄ±
    with col_rec:
        st.metric(label="ğŸ”„ Ortalama Geri Ã‡aÄŸÄ±rma (Recall)",
                  value=f"{selected_result['recall']:.4f}")

    st.write("---")

    # --- 2. SÄ±nÄ±flandÄ±rma Raporu ve KarmaÅŸÄ±klÄ±k Matrisi ---
    st.subheader("2. DetaylÄ± Metrik Analizi")
    
    col_report, col_matrix = st.columns(2)
    
    # SÄ±nÄ±flandÄ±rma Raporu
    with col_report:
        st.markdown("##### ğŸ“„ SÄ±nÄ±flandÄ±rma Raporu")
        report_df = pd.DataFrame(selected_result['report']).transpose()
        # SayÄ±sal formatÄ± dÃ¼zenleme
        for col in ['precision', 'recall', 'f1-score']:
            if col in report_df.columns:
                 report_df[col] = report_df[col].apply(lambda x: f"{x:.4f}" if isinstance(x, (int, float)) else x)
                 
        st.dataframe(report_df.style.highlight_max(axis=0, color='lightgreen', subset=pd.IndexSlice[['0', '1'], ['precision', 'recall', 'f1-score']]), 
                     use_container_width=True)
        st.caption("Not: Rapor, aÄŸÄ±rlÄ±klÄ± ortalama (weighted avg) deÄŸerleri iÃ§ermektedir.")


    # KarmaÅŸÄ±klÄ±k Matrisi
    with col_matrix:
        st.markdown("##### ğŸ“‰ KarmaÅŸÄ±klÄ±k Matrisi (Confusion Matrix)")
        
        fig, ax = plt.subplots(figsize=(6, 5))
        cm = selected_result['conf_matrix']
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=['Reddedildi (0)', 'OnaylandÄ± (1)'], 
                    yticklabels=['Reddedildi (0)', 'OnaylandÄ± (1)'],
                    ax=ax)
        ax.set_title(f"{model_name} Matrisi")
        ax.set_xlabel("Tahmin Edilen")
        ax.set_ylabel("GerÃ§ek")
        st.pyplot(fig)


# ----------------------------------------------------------------------
# 3. ANA UYGULAMA MANTIÄI
# ----------------------------------------------------------------------

def main():
    
    # 1. Veri YÃ¼kleme ve Modelleri EÄŸitme
    results, X_raw, metadata = load_data_and_train_models()
    
    if results is None:
        return

    # 2. Sayfa SeÃ§imi (Sidebar)
    PAGES = {
        "ğŸ“Š Veri HazÄ±rlÄ±ÄŸÄ± ve Genel KarÅŸÄ±laÅŸtÄ±rma": show_data_prep_page,
        "ğŸ† Model Detay ve Metrikler": show_model_comparison_page,
    }

    st.sidebar.title("Credit Approval Analizi")
    st.sidebar.markdown("---")
    
    selection = st.sidebar.radio("Sayfa SeÃ§imi", list(PAGES.keys()))
    st.sidebar.markdown("---")
    st.sidebar.success("âœ… Veri ve Modeller HazÄ±r!")
    
    # 3. SeÃ§ilen SayfayÄ± GÃ¶ster
    if selection == "ğŸ“Š Veri HazÄ±rlÄ±ÄŸÄ± ve Genel KarÅŸÄ±laÅŸtÄ±rma":
        PAGES[selection](X_raw, metadata, results) # results'Ä± karÅŸÄ±laÅŸtÄ±rma iÃ§in gÃ¶nderdik
    elif selection == "ğŸ† Model Detay ve Metrikler":
        PAGES[selection](results)

if __name__ == "__main__":
    main()
